{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이썬으로 인공 신경망 만들기\n",
    "### 뼈대 코드\n",
    "초기화 : 입력, 은닉, 출력 노드의 수 설정\n",
    "\n",
    "학습 : 학습 데이터들을 통해 학습하고 이에 따라 가중치를 업데이트\n",
    "\n",
    "질의 : 입력을 받아 연산한 후 출력 노드에서 답을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    #신경망 초기화하기\n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "    # 신경망에 질의하기\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 초기화하기\n",
    "입력 계층의 노드, 은닉 계층의 노드, 출력 계층의 노드의 수, 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 초기화하기\n",
    "def __init__(self,inputNodes,hiddenNodes,outputNodes,learningRate):\n",
    "    # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "    self.inodes = inputNodes\n",
    "    self.hnodes = hiddenNodes\n",
    "    self.onodes = outputNodes\n",
    "    \n",
    "    # 학습률\n",
    "    self.lr = learningRate\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    # 신경망 초기화하기\n",
    "    def __init__(self,inputNodes,hiddenNodes,outputNodes,learningRate):\n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputNodes\n",
    "        self.hnodes = hiddenNodes\n",
    "        self.onodes = outputNodes\n",
    "        \n",
    "        # 학습률\n",
    "        self.lr = learningRate\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "    # 신경망에 질의하기\n",
    "    def query():\n",
    "        pass\n",
    "\n",
    "# 입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# 학습률은 0.3으로 정의\n",
    "learning_rate = 0.3\n",
    "# 신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연결 노드의 가중치\n",
    "W input_hidden : (은닉 노드 * 입력 노드)의 크기를 가지는 입력 계층과 은닉 계층 사이의 가중치 행렬\n",
    "\n",
    "W hidden_output : (출력 노드 * 은닉 노드)의 크기를 가지는 은닉 계층과 출력 계층 사이의 가중치의 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 행렬 wih와 who\n",
    "# 배열 내 가중치는 w_i_j로 표기. 노드 i에서 다음 계층의 노드 j로 연결됨을 의미\n",
    "# w11 w21\n",
    "# w21 w22 등\n",
    "import numpy\n",
    "\n",
    "self.wih=numpy.random.normal(0.0,pow(self.inodes, -0.5),(self.hnodes,self.inodes))\n",
    "self.who=numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.onodes,self.hnodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에 질의하기\n",
    "X=W*I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_inputs=numpy.dot(self.wih,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수 적용\n",
    "\n",
    "O=sigmoid(Xhidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수로 시그모이드 함수를 이용\n",
    "self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "# 은닉 계층에서 나가는 신호를 계산\n",
    "hidden_outputs=self.activation_function(hidden_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    # 신경망 초기화하기\n",
    "    def __init__(self,inputNodes,hiddenNodes,outputNodes,learningRate):\n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputNodes\n",
    "        self.hnodes = hiddenNodes\n",
    "        self.onodes = outputNodes\n",
    "        \n",
    "        # 학습률\n",
    "        self.lr = learningRate\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        # 배열 내 가중치는 w_i_j로 표기. 노드 i에서 다음 계층의 노드 j로 연결됨을 의미\n",
    "        # w11 w21\n",
    "        # w21 w22 등\n",
    "\n",
    "        self.wih=numpy.random.normal(0.0,pow(self.inodes, -0.5),(self.hnodes,self.inodes))\n",
    "        self.who=numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.onodes,self.hnodes))\n",
    "        \n",
    "        # 활성화 함수로는 시그모이드 함수를 이용\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "    \n",
    "    #신경망 학습시키기\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "    # 신경망에 질의하기\n",
    "    def query(self,input_list):\n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(input_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        # 은닉 계층에서 나가는 신호를 계싼\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        \n",
    "\n",
    "# 입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# 학습률은 0.3으로 정의\n",
    "learning_rate = 0.3\n",
    "# 신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55420071],\n",
       "       [0.51766414],\n",
       "       [0.45956106]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 학습시키기\n",
    "1. 주어진 학습 데이터에 대해 결과값을 계산\n",
    "2. 방금 계산한 결과 값을 실제의 값과 비교하고 이 차이를 이용해 가중치를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 학습시키기\n",
    "def train(self, input_list, target_list):\n",
    "    #입력 리스트를 2차원의 행렬로 변환\n",
    "    input=numpy.array(input_list,ndmin=2).T\n",
    "    target=numpy.array(target_list,ndmin=2).T\n",
    "    \n",
    "    #은닉 계층으로 들어오는 신호를 계산\n",
    "    hidden_inputs=numpy.dot(self.wih, input)\n",
    "    #은닉 계층에서 나가는 신호를 계산\n",
    "    hidden_outputs=self.activation_function(hidden_inputs)\n",
    "    \n",
    "    #최종 출력 계층으로 들어오는 신호를 계산\n",
    "    final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "    \n",
    "    #최종 출력 계층에서 나가는 신호를 계산\n",
    "    final_outputs=self.activation_function(final_inputs)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오차 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차는 (실제 값 - 계산 값)\n",
    "output_errors=target-final_outputs\n",
    "\n",
    "# 은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "hidden_errors=numpy.dot(self.who.T, output_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완성된 신경망 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "\n",
    "# 신경망 클래스의 정의\n",
    "class neuralNetwork:\n",
    "    # 신경망 초기화하기\n",
    "    def __init__(self,inputNodes,hiddenNodes,outputNodes,learningRate):\n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        self.inodes = inputNodes\n",
    "        self.hnodes = hiddenNodes\n",
    "        self.onodes = outputNodes\n",
    "        \n",
    "        # 학습률\n",
    "        self.lr = learningRate\n",
    "        \n",
    "        # 가중치 행렬 wih와 who\n",
    "        # 배열 내 가중치는 w_i_j로 표기. 노드 i에서 다음 계층의 노드 j로 연결됨을 의미\n",
    "        # w11 w21\n",
    "        # w21 w22 등\n",
    "        self.wih=numpy.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes,self.inodes))\n",
    "        self.who=numpy.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes,self.hnodes))\n",
    "        \n",
    "        # 활성화 함수로는 시그모이드 함수를 이용\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "    \n",
    "    # 신경망 학습시키기\n",
    "    def train(self, input_list, target_list):\n",
    "        #입력 리스트를 2차원의 행렬로 변환\n",
    "        input=numpy.array(input_list,ndmin=2).T\n",
    "        target=numpy.array(target_list,ndmin=2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=numpy.dot(self.wih, input)\n",
    "        #은닉 계층에서 나가는 신호를 계산\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "        \n",
    "        #최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        # 오차는 (실제 값 - 계산 값)\n",
    "        output_errors=target-final_outputs\n",
    "\n",
    "        # 은닉 계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors=numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트\n",
    "        self.who += self.lr*numpy.dot((output_errors*final_outputs*(1.0-final_outputs)),numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.wih += self.lr*numpy.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)),numpy.transpose(input))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # 신경망에 질의하기\n",
    "    def query(self,input_list):\n",
    "        # 입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(input_list, ndmin=2).T\n",
    "        \n",
    "        # 은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs=numpy.dot(self.wih,inputs)\n",
    "        # 은닉 계층에서 나가는 신호를 계싼\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        # 최종 출력 계층으로 들어오는 신호를 계산\n",
    "        final_inputs=numpy.dot(self.who,hidden_outputs)\n",
    "        # 최종 출력 계층에서 나가는 신호를 계산\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        \n",
    "\n",
    "# 입력, 은닉, 출력 노드의 수\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# 학습률은 0.3으로 정의\n",
    "learning_rate = 0.3\n",
    "# 신경망의 인스턴스를 생성\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
